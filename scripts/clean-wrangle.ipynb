{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and Wrangle Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe of Compiled Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output a .csv file with all the text and metadata for each turn under `/output_data/uncooked`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# <!-- Compile all input_data --> #\n",
    "def compile_transcripts():\n",
    "    empathy_compiled_df = pd.DataFrame({\"speaker_turn\": [],\n",
    "                                        \"timestamp\": [],\n",
    "                                        \"conversation_text\": [],\n",
    "                                        \"transcript_number\": []})\n",
    "\n",
    "    # <!-- Loop over all transcripts to extract speaker turn, timestamp, convo text, and transcript number --> #\n",
    "    for transcript in sorted(glob('../input_data/NR/*.txt')):\n",
    "        # <!-- Transcript being looped over --> #\n",
    "        transcript_num = transcript.lstrip('../input_data/NR/')[0:4]\n",
    "\n",
    "        # <!-- RegEx to find the speaker turns and timestamps and use as delimiter to isolate conversation text --> #\n",
    "        frag_df = pd.read_csv(transcript,\n",
    "                              sep=r\"S\\w+[(\\s)(\\s\\d\\s)]+\\(\\d{2}:\\d{2}\\):\",\n",
    "                              engine=\"python\").rename(\n",
    "            columns={\"Unnamed: 0\": \"conversation_text\", \"Unnamed: 1\": \"to_be_dropped\"}).drop(\n",
    "            columns=['to_be_dropped']).dropna()\n",
    "\n",
    "        # <!-- RegEx to find the speaker turns and timestamps and isolate them --> #\n",
    "        with open(transcript, 'r') as plain_text:\n",
    "            plain_text = plain_text.read().replace('\\n', ' ')\n",
    "            timestamps = re.findall(r\"S\\w+[(\\s)(\\s\\d\\s)]+\\(\\d{2}:\\d{2}\\):\", plain_text)\n",
    "            timestamps_df = pd.DataFrame(timestamps).iloc[:, 0].str.split(\n",
    "                r\" \\(\", expand=True).rename(\n",
    "                columns={0: \"speaker_turn\", 1: \"timestamp\"})\n",
    "            timestamps_df[\"timestamp\"] = timestamps_df[\"timestamp\"].str.rstrip('):')\n",
    "            empathy_compiled_part_df = pd.concat([timestamps_df.reset_index(drop=True),\n",
    "                                                  frag_df.reset_index(drop=True)], axis=1)\n",
    "            empathy_compiled_part_df['transcript_number'] = transcript_num\n",
    "        empathy_compiled_df = pd.concat([empathy_compiled_df, empathy_compiled_part_df])\n",
    "        empathy_compiled_df = empathy_compiled_df.reindex(\n",
    "            ['transcript_number', 'speaker_turn', 'timestamp', 'conversation_text'],\n",
    "            axis=1)\n",
    "    return empathy_compiled_df\n",
    "\n",
    "\n",
    "# <!-- Get speaker and overall turn counts --> #\n",
    "def compile_transcript_turns(df):\n",
    "    raw_transcripts_compiled_df = pd.DataFrame({\"speaker_turn\": [],\n",
    "                                                \"timestamp\": [],\n",
    "                                                \"conversation_text\": [],\n",
    "                                                \"transcript_number\": []})\n",
    "    for transcript in sorted(set(df['transcript_number'].to_list())):\n",
    "        sub_df = df.loc[df['transcript_number'] == transcript].copy()\n",
    "        speaker_turn_count = []\n",
    "        speaker_1_count = speaker_2_count = researcher_count = 0\n",
    "        raw_transcripts_compiled_df = pd.concat([raw_transcripts_compiled_df, sub_df])\n",
    "\n",
    "    # <!-- Change all \"[laugh-]\" segments to \"[laugh]\" --> #\n",
    "    raw_transcripts_compiled_df['conversation_text'] = raw_transcripts_compiled_df['conversation_text'].str.replace(\n",
    "        r'\\[([Ll]augh)[A-Za-z]*\\]',\n",
    "        '[laugh]', regex=True)\n",
    "\n",
    "    # <!-- Add all annotations set off in square brackets to a new column, \"other_text\" --> #\n",
    "    raw_transcripts_compiled_df['other_text'] = raw_transcripts_compiled_df['conversation_text'].str.findall(\n",
    "        r'\\[(.*?)\\]')\n",
    "\n",
    "    # <!-- Drop all annotations set off in square brackets from the \"conversation_text\" column --> #\n",
    "    raw_transcripts_compiled_df['conversation_text'] = raw_transcripts_compiled_df['conversation_text'].str.replace(\n",
    "        r'\\s*\\[(.*?)\\]',  # Make sure you catch the space before itâ€”if it's there\n",
    "        '', regex=True)\n",
    "\n",
    "    # <!-- Strip whitespace and fill in empty cells with \".\" that previously only held text set off in square brackets --> #\n",
    "    raw_transcripts_compiled_df['condition'] = np.where(\n",
    "        raw_transcripts_compiled_df['transcript_number'].astype(float) % 2 == 0, \"control\", \"empathy\")\n",
    "\n",
    "    # <!-- Write to .csv file --> #\n",
    "    raw_transcripts_compiled_df.to_csv(\"../output_data/uncooked/S0_raw_transcripts_compiled.csv\", index=False)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    empathy_precompiled_df = compile_transcripts()\n",
    "    compile_transcript_turns(empathy_precompiled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backchanneling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are *two* different versions of the dataset:\n",
    "1. No laughs: any nonverbal contribution to the conversation (laughs) are swung into a separate column, and the turns immediately preceding and succeeding it are spliced together\n",
    "2. No laughs, no backchanneling: any backchanneling terms are swung into an additional separate column, and the turns immediately preceding and succeeding it are spliced together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages + Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# <!-- Data Wrangling --> #\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import accumulate\n",
    "import re\n",
    "\n",
    "# <!-- NLP --> #\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# <!-- Read in Data --> #\n",
    "transcripts_compiled_df = pd.read_csv(\"../output_data/uncooked/S0_raw_transcripts_compiled.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete `\".\"` Left Behind From Extracting Text Set Off in `\"[]\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_compiled_df.loc[transcripts_compiled_df['conversation_text'].isna(), 'conversation_text'] = \"np.nan_filler\"\n",
    "transcripts_compiled_df.loc[transcripts_compiled_df['conversation_text'] == \"\", 'conversation_text'] = \"np.nan_filler\"\n",
    "transcripts_compiled_df.loc[transcripts_compiled_df['conversation_text'].str.contains(r\"^[.]+$\", regex=True), 'conversation_text'] = \"np.nan_filler\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip Text of Punctuation, Half-Spoken Words and Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_compiled_df[\"conversation_text\"] = transcripts_compiled_df[\"conversation_text\"].str.replace(\"...\", \" \", regex=False)\n",
    "transcripts_compiled_df[\"conversation_text\"] = transcripts_compiled_df[\"conversation_text\"].str.replace(\", .\", \".\", regex=False)\n",
    "transcripts_compiled_df[\"conversation_text\"] = transcripts_compiled_df[\"conversation_text\"].str.replace(\" . \", \". \", regex=False)\n",
    "transcripts_compiled_df[\"conversation_text\"] = transcripts_compiled_df[\"conversation_text\"].str.replace(\"..\", \".\", regex=False)\n",
    "transcripts_compiled_df[\"conversation_text\"] = transcripts_compiled_df[\"conversation_text\"].str.replace(\",,\", \",\", regex=False)\n",
    "transcripts_compiled_df[\"conversation_text\"] = transcripts_compiled_df[\"conversation_text\"].str.replace(\"  \", \" \", regex=False)\n",
    "transcripts_compiled_df[\"conversation_text\"] = transcripts_compiled_df[\"conversation_text\"].str.replace('\"', \"\", regex=False)\n",
    "transcripts_compiled_df[\"conversation_text\"] = transcripts_compiled_df[\"conversation_text\"].str.replace(\"\\w+-\\s\", \"\", regex=True)  # drop half-spoken words, and not just the ones at the end of a line\n",
    "transcripts_compiled_df[\"conversation_text\"] = transcripts_compiled_df[\"conversation_text\"].str.strip(\"-\")\n",
    "transcripts_compiled_df[\"conversation_text\"] = transcripts_compiled_df[\"conversation_text\"].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a `.loc` to remove the \". \" leading the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_compiled_df.loc[transcripts_compiled_df[\"conversation_text\"].str.startswith(\". \"), 'conversation_text'] = transcripts_compiled_df.loc[transcripts_compiled_df[\"conversation_text\"].str.startswith(\". \"), 'conversation_text'].str.lstrip(\". \")\n",
    "transcripts_compiled_df.loc[transcripts_compiled_df[\"conversation_text\"].str.startswith(\", \"), 'conversation_text'] = transcripts_compiled_df.loc[transcripts_compiled_df[\"conversation_text\"].str.startswith(\", \"), 'conversation_text'].str.lstrip(\", \")\n",
    "transcripts_compiled_df.loc[transcripts_compiled_df[\"conversation_text\"].str.endswith(\",\"), 'conversation_text'] = transcripts_compiled_df.loc[transcripts_compiled_df[\"conversation_text\"].str.endswith(\",\"), 'conversation_text'].str.rstrip(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_compiled_df.loc[transcripts_compiled_df['conversation_text'].isna(), 'conversation_text'] = \"np.nan_filler\"\n",
    "transcripts_compiled_df.loc[transcripts_compiled_df['conversation_text'] == '', 'conversation_text'] = \"np.nan_filler\"\n",
    "transcripts_compiled_df.loc[transcripts_compiled_df['conversation_text'] == \"''\", 'conversation_text'] = \"np.nan_filler\"\n",
    "\n",
    "transcripts_compiled_df.loc[transcripts_compiled_df['conversation_text'].str.contains(r\"^[.]+$\", regex=True), 'conversation_text'] = \"np.nan_filler\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Null Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_turn</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>conversation_text</th>\n",
       "      <th>transcript_number</th>\n",
       "      <th>other_text</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>00:14</td>\n",
       "      <td>All right. Um, so you just click the next butt...</td>\n",
       "      <td>1003</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>00:19</td>\n",
       "      <td>Uh, I guess so, yeah. Let's see. Uh, okay. Yea...</td>\n",
       "      <td>1003</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>00:33</td>\n",
       "      <td>I don't, are we allowed to say what our name is?</td>\n",
       "      <td>1003</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>00:34</td>\n",
       "      <td>Oh, are we not allowed to? I don't know. Maybe...</td>\n",
       "      <td>1003</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>00:38</td>\n",
       "      <td>I have no idea. Okay. Let's just do benefit of...</td>\n",
       "      <td>1003</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6448</th>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>20:27</td>\n",
       "      <td>But maybe it'll come, like, 10 years down the ...</td>\n",
       "      <td>1049</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6449</th>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>20:30</td>\n",
       "      <td>Yeah. And maybe you don't need that moment.</td>\n",
       "      <td>1049</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>20:31</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>1049</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6451</th>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>20:32</td>\n",
       "      <td>Because like you're not as aligned in somethin...</td>\n",
       "      <td>1049</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6452</th>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>20:40</td>\n",
       "      <td>Yeah, um, mine's at zero. Should we, like, cli...</td>\n",
       "      <td>1049</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6453 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     speaker_turn timestamp  \\\n",
       "0       Speaker 1     00:14   \n",
       "1       Speaker 2     00:19   \n",
       "2       Speaker 1     00:33   \n",
       "3       Speaker 2     00:34   \n",
       "4       Speaker 1     00:38   \n",
       "...           ...       ...   \n",
       "6448    Speaker 2     20:27   \n",
       "6449    Speaker 1     20:30   \n",
       "6450    Speaker 2     20:31   \n",
       "6451    Speaker 1     20:32   \n",
       "6452    Speaker 2     20:40   \n",
       "\n",
       "                                      conversation_text  transcript_number  \\\n",
       "0     All right. Um, so you just click the next butt...               1003   \n",
       "1     Uh, I guess so, yeah. Let's see. Uh, okay. Yea...               1003   \n",
       "2      I don't, are we allowed to say what our name is?               1003   \n",
       "3     Oh, are we not allowed to? I don't know. Maybe...               1003   \n",
       "4     I have no idea. Okay. Let's just do benefit of...               1003   \n",
       "...                                                 ...                ...   \n",
       "6448  But maybe it'll come, like, 10 years down the ...               1049   \n",
       "6449        Yeah. And maybe you don't need that moment.               1049   \n",
       "6450                                              Yeah.               1049   \n",
       "6451  Because like you're not as aligned in somethin...               1049   \n",
       "6452  Yeah, um, mine's at zero. Should we, like, cli...               1049   \n",
       "\n",
       "     other_text condition  \n",
       "0            []   empathy  \n",
       "1            []   empathy  \n",
       "2            []   empathy  \n",
       "3            []   empathy  \n",
       "4            []   empathy  \n",
       "...         ...       ...  \n",
       "6448         []   empathy  \n",
       "6449         []   empathy  \n",
       "6450         []   empathy  \n",
       "6451         []   empathy  \n",
       "6452         []   empathy  \n",
       "\n",
       "[6453 rows x 6 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts_compiled_df = transcripts_compiled_df[transcripts_compiled_df['conversation_text'] != \"np.nan_filler\"].reset_index(drop=True)\n",
    "transcripts_compiled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_turn</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>conversation_text</th>\n",
       "      <th>transcript_number</th>\n",
       "      <th>other_text</th>\n",
       "      <th>condition</th>\n",
       "      <th>speaker_turn_shifted</th>\n",
       "      <th>transcript_number_shifted</th>\n",
       "      <th>repeat_turn_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>00:14</td>\n",
       "      <td>All right. Um, so you just click the next butt...</td>\n",
       "      <td>1003</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_repeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>00:19</td>\n",
       "      <td>Uh, I guess so, yeah. Let's see. Uh, okay. Yea...</td>\n",
       "      <td>1003</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>no_repeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>00:33</td>\n",
       "      <td>I don't, are we allowed to say what our name is?</td>\n",
       "      <td>1003</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>no_repeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>00:34</td>\n",
       "      <td>Oh, are we not allowed to? I don't know. Maybe...</td>\n",
       "      <td>1003</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>no_repeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>00:38</td>\n",
       "      <td>I have no idea. Okay. Let's just do benefit of...</td>\n",
       "      <td>1003</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>no_repeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6448</th>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>20:27</td>\n",
       "      <td>But maybe it'll come, like, 10 years down the ...</td>\n",
       "      <td>1049</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>no_repeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6449</th>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>20:30</td>\n",
       "      <td>Yeah. And maybe you don't need that moment.</td>\n",
       "      <td>1049</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>no_repeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>20:31</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>1049</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>no_repeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6451</th>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>20:32</td>\n",
       "      <td>Because like you're not as aligned in somethin...</td>\n",
       "      <td>1049</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>no_repeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6452</th>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>20:40</td>\n",
       "      <td>Yeah, um, mine's at zero. Should we, like, cli...</td>\n",
       "      <td>1049</td>\n",
       "      <td>[]</td>\n",
       "      <td>empathy</td>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>no_repeat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6453 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     speaker_turn timestamp  \\\n",
       "0       Speaker 1     00:14   \n",
       "1       Speaker 2     00:19   \n",
       "2       Speaker 1     00:33   \n",
       "3       Speaker 2     00:34   \n",
       "4       Speaker 1     00:38   \n",
       "...           ...       ...   \n",
       "6448    Speaker 2     20:27   \n",
       "6449    Speaker 1     20:30   \n",
       "6450    Speaker 2     20:31   \n",
       "6451    Speaker 1     20:32   \n",
       "6452    Speaker 2     20:40   \n",
       "\n",
       "                                      conversation_text  transcript_number  \\\n",
       "0     All right. Um, so you just click the next butt...               1003   \n",
       "1     Uh, I guess so, yeah. Let's see. Uh, okay. Yea...               1003   \n",
       "2      I don't, are we allowed to say what our name is?               1003   \n",
       "3     Oh, are we not allowed to? I don't know. Maybe...               1003   \n",
       "4     I have no idea. Okay. Let's just do benefit of...               1003   \n",
       "...                                                 ...                ...   \n",
       "6448  But maybe it'll come, like, 10 years down the ...               1049   \n",
       "6449        Yeah. And maybe you don't need that moment.               1049   \n",
       "6450                                              Yeah.               1049   \n",
       "6451  Because like you're not as aligned in somethin...               1049   \n",
       "6452  Yeah, um, mine's at zero. Should we, like, cli...               1049   \n",
       "\n",
       "     other_text condition speaker_turn_shifted  transcript_number_shifted  \\\n",
       "0            []   empathy                  NaN                        NaN   \n",
       "1            []   empathy            Speaker 1                     1003.0   \n",
       "2            []   empathy            Speaker 2                     1003.0   \n",
       "3            []   empathy            Speaker 1                     1003.0   \n",
       "4            []   empathy            Speaker 2                     1003.0   \n",
       "...         ...       ...                  ...                        ...   \n",
       "6448         []   empathy            Speaker 1                     1049.0   \n",
       "6449         []   empathy            Speaker 2                     1049.0   \n",
       "6450         []   empathy            Speaker 1                     1049.0   \n",
       "6451         []   empathy            Speaker 2                     1049.0   \n",
       "6452         []   empathy            Speaker 1                     1049.0   \n",
       "\n",
       "     repeat_turn_check  \n",
       "0            no_repeat  \n",
       "1            no_repeat  \n",
       "2            no_repeat  \n",
       "3            no_repeat  \n",
       "4            no_repeat  \n",
       "...                ...  \n",
       "6448         no_repeat  \n",
       "6449         no_repeat  \n",
       "6450         no_repeat  \n",
       "6451         no_repeat  \n",
       "6452         no_repeat  \n",
       "\n",
       "[6453 rows x 9 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts_compiled_df[\"speaker_turn_shifted\"] = transcripts_compiled_df[\"speaker_turn\"].shift()\n",
    "transcripts_compiled_df[\"transcript_number_shifted\"] = transcripts_compiled_df[\"transcript_number\"].shift()\n",
    "\n",
    "transcripts_compiled_df[\"repeat_turn_check\"] = np.where(\n",
    "    (transcripts_compiled_df[\"speaker_turn_shifted\"] == transcripts_compiled_df[\"speaker_turn\"]) &\n",
    "    (transcripts_compiled_df[\"transcript_number_shifted\"] == transcripts_compiled_df[\"transcript_number\"]), \n",
    "    \"repeat\",\n",
    "    \"no_repeat\")\n",
    "transcripts_compiled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splice together rows of text from same speaker punctuated by laugh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13      Uh, sure. Let's see. Uh, um, let's see, wake u...\n",
       "38      Uh, sure, yeah. Um, let's see. I think this wa...\n",
       "66      Uh, yeah. I'd like to play baseball. It's kind...\n",
       "70      And be like, All right, guess I'll go work on ...\n",
       "161     Yeah. They kinda real deep. I don't know how, ...\n",
       "                              ...                        \n",
       "6378    Um, I think I want to eventually do a PhD. Um,...\n",
       "6388    Because I think I came in with the philosophy ...\n",
       "6415    So like, um, I don't I feel like there for me,...\n",
       "6418    So hearing you talk about how, like, for you a...\n",
       "6440    Yeah. No, uh, what you're saying about guilt i...\n",
       "Name: conversation_text, Length: 184, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat_idx = transcripts_compiled_df.index[transcripts_compiled_df['repeat_turn_check'] == \"repeat\"]\n",
    "\n",
    "transcripts_compiled_df.loc[repeat_idx - 1, 'conversation_text'] = transcripts_compiled_df.loc[repeat_idx - 1, 'conversation_text'].str.cat(\n",
    "    transcripts_compiled_df.loc[repeat_idx, 'conversation_text'].to_list(), sep=\" \")\n",
    "\n",
    "transcripts_compiled_df.loc[repeat_idx - 1, 'conversation_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop repeat speaker rows from which you have already extracted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_compiled_df.drop(transcripts_compiled_df.loc[repeat_idx, 'conversation_text'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_turn</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>conversation_text</th>\n",
       "      <th>transcript_number</th>\n",
       "      <th>other_text</th>\n",
       "      <th>condition</th>\n",
       "      <th>speaker_turn_shifted</th>\n",
       "      <th>transcript_number_shifted</th>\n",
       "      <th>repeat_turn_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [speaker_turn, timestamp, conversation_text, transcript_number, other_text, condition, speaker_turn_shifted, transcript_number_shifted, repeat_turn_check]\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts_compiled_df[transcripts_compiled_df[\"repeat_turn_check\"] == \"repeat\"]  # No more repeats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_compiled_df.drop(columns=['speaker_turn_shifted', 'transcript_number_shifted', 'repeat_turn_check'], inplace=True)  # We also don't need these vestigial columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_compiled_df.reset_index(drop=True)\n",
    "\n",
    "# <!-- Get speaker and overall turn counts --> #\n",
    "transcripts_compiled_df.insert(\n",
    "    1, 'overall_turn_count', transcripts_compiled_df.groupby(\n",
    "    'transcript_number').cumcount() + 1)  # +1 to reflect next turn of the entire conversation\n",
    "transcripts_compiled_df.insert(\n",
    "    2, 'speaker_turn_count', transcripts_compiled_df.groupby(\n",
    "    ['speaker_turn', 'transcript_number']).cumcount() + 1)  # +1 to reflect next turn of the specific participant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Through Pre-Trained Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transcripts_compiled_df[\"conversation_text_nlp_vectors\"] = transcripts_compiled_df[\"conversation_text\"].apply(lambda x: nlp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Columns for NLP Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_compiled_df[\"token_lemma\"] = transcripts_compiled_df[\"conversation_text_nlp_vectors\"].apply(lambda x: [token.lemma_ for token in x])\n",
    "transcripts_compiled_df[\"token_pos\"] = transcripts_compiled_df[\"conversation_text_nlp_vectors\"].apply(lambda x: [token.pos_ for token in x])\n",
    "transcripts_compiled_df[\"token_tag\"] = transcripts_compiled_df[\"conversation_text_nlp_vectors\"].apply(lambda x: [token.tag_ for token in x])\n",
    "transcripts_compiled_df[\"token_dep\"] = transcripts_compiled_df[\"conversation_text_nlp_vectors\"].apply(lambda x: [token.dep_ for token in x])\n",
    "transcripts_compiled_df[\"token_shape\"] = transcripts_compiled_df[\"conversation_text_nlp_vectors\"].apply(lambda x: [token.shape_ for token in x])\n",
    "transcripts_compiled_df[\"token_is_alpha\"] = transcripts_compiled_df[\"conversation_text_nlp_vectors\"].apply(lambda x: [token.is_alpha for token in x])\n",
    "transcripts_compiled_df[\"token_is_stop\"] = transcripts_compiled_df[\"conversation_text_nlp_vectors\"].apply(lambda x: [token.is_stop for token in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length of Responses With and Without Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_compiled_df[\"token_lemma_len\"] = transcripts_compiled_df[\"token_lemma\"].apply(len)\n",
    "transcripts_compiled_df[\"token_lemma_len_no_punct\"] = transcripts_compiled_df[\"token_pos\"].apply(len) - transcripts_compiled_df[\"token_pos\"].apply(lambda x: x.count(\"PUNCT\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert timestamps to `datetime` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_compiled_df['timestamp'] = pd.to_datetime(transcripts_compiled_df['timestamp'], format='%M:%S')\n",
    "transcripts_compiled_df.insert(4, 'timestamp_delta', (transcripts_compiled_df['timestamp'] - transcripts_compiled_df['timestamp'].shift()).fillna(pd.Timedelta('0 days')).astype(str).str[7:])\n",
    "transcripts_compiled_df['timestamp_delta'] = transcripts_compiled_df['timestamp_delta'].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. No Laughs Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_compiled_df.to_csv(\"../output_data/cooked/final_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Notebook to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook clean-wrangle.ipynb to html\n",
      "[NbConvertApp] Writing 807806 bytes to clean-wrangle.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('jupyter nbconvert --to html clean-wrangle.ipynb')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42f2f582df0d745ce9ae5ad2c51ba937c4c06768402537a9b9f2ee10e1bff018"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('PSNL_Spock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
